## Are you feeling lost and unsure about bioinformatic anaysis?

* Do you want to utilize high-throughput sequencing data in your research, but not really sure where to start?
* Does the idea of writing your own code for data analysis seem necessary, yet daunting?
* Do you need to brush up on what you already know about analysis of high-throughput sequencing data?

### If the answer to any of the questions is yes, or even maybe, then you are on the right page! 

Before we tell you about [our program](), we want to describe some of the jargon & concepts you will encounter. If you are familiar with the concepts below, you can [skip them]().

## What the heck is 'omics?

Over the last 10-20 years many technological advances allow us to assess the entirety of a certain type of molecule(s) in an organsim. The resulting high-throughput data are called 'omics data. We can break 'omics down into 4 specific categories:

* genOMICS - The study of the complete set of **DNA** in an organism, sigle cell, or group of cells.
* transcriptOMICS - The study of the complete set of **RNA** in an organism, sigle cell, or group of cells.
* proteOMICS - The study of the complete set of **Proteins** in an organism, sigle cell, or group of cells.
* metabolOMICS - The study of the complete set of **Metabolites** in an organism, sigle cell, or group of cells.

High-throughput data from even a *single sample* is considered 'omics data. However, we usually are looking at data from large number of biological samples (individuals, cell lines, etc).

***We will be focusing the rest of these Q&As around Genomics and Transcriptomics!***

## High-throughput Sequencing (HTS) or Next-generation Sequencing (NGS)

* What is a Genome? *the complete set of **DNA** in an organism, sigle cell, or group of cells*
* What is a Transcriptome? *the complete set of **RNA** in an organism, sigle cell, or group of cells*

Both, genomes and transcriptomes, contain hundreds of millions or billions of nucleic acid units or [bases/base pairs](https://en.wikipedia.org/wiki/Base_pair) (A,T,G,C). Compare that to the average length of a book, which is 375,000 characters. To "read" the sequence of As, Ts, Gs and Cs, we use different methods (a lot of which are [PCR](https://en.wikipedia.org/wiki/Polymerase_chain_reaction)-based). The most basic way to sequence DNA is using [Sanger Sequencing](https://en.wikipedia.org/wiki/Sanger_sequencing). Just like you reading a book, the Sanger method reads bases one at time. Using the Sanger method for a whole genome takes a very long time with high per-base costs, but it was creatively utilized to complete the [Human Genome Project (HGP) 1990 - 2003](https://en.wikipedia.org/wiki/Human_Genome_Project). 

With the massive advancements spurred by the HGP, the field of "next-generation" sequencing (with Sanger considered *first* generation) exploded and had rapidly advanced such that now we are able to sequence a whole genome within a day, at a nominal cost. The analyses of these **big data** generated by HTS is the challenge at present.

> Over the last few years the community has been slowly replacing the term NGS (Next-generation Sequencing) with the more descriptive HTS (High-throughput Sequencing).

There are [hundreds of assays](https://www.illumina.com/science/sequencing-method-explorer.html) that have been developed for HTS that have enabled us to gain deep insights into the working of a cell, tissue, or organism. The most commonly used HTS applications that you will encounter are:
* Bulk RNA-seq
* Single-cell RNA-seq
* ChIP-seq
* Whole genome sequencing
* Exome sequencing
* ATAC-seq
* Single-cell ATAC-seq

## What is High Throughput Sequencing (HTS)?

Genomes and transcriptomes, etc are massive data sets containing hundreds of millions or billions of [base pairs](https://en.wikipedia.org/wiki/Base_pair) (A,T,G,C). For a comparison, an average length book might have about 375,000 characters. Reading those bases one at a time will take too long even for a fast machine. **H**igh **T**hroughput **S**equencing (HTS) is when multiple DNA or RNA moleculars are sequenced in parallel (i.e., at the same time). This leads to hundreds of millions of molecules being sequenced at one time. Because only DNA and RNA are sequenced, HTS is used for genomics and transcriptomics. However, newer methodologies allow information about chromatin and proteins to be incorporated with this data.

## What is a High-Performance Cluster (HPC)?

An HPC, or called **cluster** for short, is a large interconnected system of many high-powered computers. It provides all the resources needed to perform analysis on large amounts of data, as well as analyses requiring very high amounts of RAM (memory).

Let's take a quick look at the basic architecture of a cluster environment and some cluster-specific jargon.

<p align="center">
<img src="img/cluster.png" width="500">
</p>

The above image reflects the many computers that make up a **"cluster"** of computers. Each individual computer in the cluster is usually a lot more powerful than any laptop or desktop computer we are used to working with, and is referred to as a **"node"** (instead of computer). Each node has a designated role, either for logging in or for performing computational analysis/work. **A given cluster will usually have a few login nodes and several compute nodes.** Each individual node in an HPC environment is a lot **more powerful** than any laptop or desktop computer we are used to working with. What we mean by *powerful* here is that each of these nodes have:

  * a lot more memory (temporary storage)
  * many more, faster CPUs
  * each of those CPUs has many more cores

E.g. A cluster “Node” that has eight “quad"-core CPUs, means that node has 32 cores (ability to process 32 computations at a time!)

The data on a cluster is also stored differently than what we are used to with our laptops and desktops, in that it is not computer- or node-specific storage, but it is external and is available to all the nodes in a cluster. This ensures that you don't have to worry about which node is working on your analysis.

## How do clusters and HPC relate to analysis of HTS data?

Let's return to our book example. If one book is 375,000 characters then 3.2 billion characters (the size of the human genome) translates to 8,533 books! While we might keep tens or even hundreds of books at our house, most people will never have thousands. 

<p align="center">
<img src="img/library.jpg" width="500">
</p>
<p align = "center">
Can you imagine dusting this?
</p>

It's the same with our local computer.  While we might keep small data files on our laptop, we don't want to clutter it up with huge data files. And this is just thinking about storage! Books or data sets need to be organized and kept track of as well. You might be able to alphabetize or organize a hundred books on your own but working with >8,000 books would be overwhelming! The same goes for our computer. To organize billions of basepairs and make sense of our sequencing data we simply need more power. Your "pretty good" laptop might have 16 cores. In comparison, a cluster (HPC) might have hundreds of cores. That is a lot more power for the big computational work we want to do!

## Do I need a HPC for analyses, when I have a pretty good laptop?

1. A lot of software is designed to work with the resources on an HPC environment and is either unavailable for, or unusable on, a personal computer.
2. If you are performing analysis on large data files (e.g. high-throughput sequencing data), you should work on the cluster to avoid issues with memory and to get the analysis done a lot faster with the superior processing capacity. Essentially, a cluster has:

<h4 align="center">    * 100s of cores for processing! </h4>
 <h4 align="center">   * 100s of Gigabytes or Petabytes of storage!</h4>
 <h4 align="center">   * 100s of Gigabytes of memory!</h4>

## What is shell and how does it relate to clusters?

So how might you actually use a cluster? Unfortunately you can't just walk up to where the cluster is stored and start using it. Clusters are accessed remotely, that means that you connect to the cluster from your own computer. You will do this from the **command line** or a text-based user interface. We are used to clicking on applications we want to use and selecting various commands from dropdown menus. Clusters do not work this way; any task that you want a cluster to do has to be communicated through a text command.

<p align="center">
<img src="img/fasRC.jpeg" width="650">
</p>
<p align = "center">
The FAS-RC Cluster
</p>

If you have never done any coding before or worked with clusters before the idea of using a computer by sending it text commands or using ***the shell*** will be brand new to you. The shell interprets your text commands into binary. Operating systems on the cluster (as well as your mac) all use the shell, most commnly the [Bash](https://en.wikipedia.org/wiki/Bash_Unix_shell) shell. You type in commands using shell syntax (the language shell understands), and shell takes care of the rest. 

As you get into HTS and computational work you will encounter a lot of languages such as Python, Perl, Fortran, R, C++, Java and more. You can think of these as being akin to human languages; French and English sound very different and have different syntax (the order of words) but can be used to convey the same message. At HBC training we recommend that you become familiar (or fluent) in bash and R to begin with.    

## What is R and what can it do?

Why do we recommend R instead of other languages? According to [R-project](https://www.r-project.org/about.html) R is "R is a language and environment for statistical computing and graphics." R is also a well developed and relatively simple language that is widely used among data scientists and people in STEM. Compelling arguements for learning R include:

* It’s open-source. This means no fees or licenses are needed and you won't get any pop ups asking for money.
* It’s platform-independent. This means that R runs on all operating systems (mac, windows, unix) and R scripts written on on platform can be run on any other platform.
* People write packages for R, especially in the field of bioinformatics. The R language has more than 10,000 packages stored in the CRAN repository, and that number is continuously increasing. Many packages for analyzing HTS data are written for R such as DESeq2 and Seurat among other.
* Data wrangling, i.e., turning raw data into the desired format. Data wrangling is necessary for working with any 'omics data set and R has many packages that can turn unstructured, messy data into a structured format.
* Great plotting programs. R has wonderful packages to make publication ready figures. We even have a [workshop](https://hbctraining.github.io/Training-modules/publication_perfect/) devoted to it!
* It’s great for statistics. Unlike SAS which is very costly, R is free and has many different statistical packages available.
* You can use R for Machine Learning. R is ideal for machine learning operations such as regression and classification and even for artificial neural network development.
* R is growing. R has a solid support program and help with issues is widely available. New packages and features are available regularly! 

## Where do I go from here?

Hopefully you now feel like you have a grasp on some of these terms. If you want to start getting your hands wet, we recommend that you take a look at our training program. <INCLUDE LINK TO THE MAIN_DRAFT PAGE HERE?>
 
 Happy Computing!




