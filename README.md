<h1 align="center">
Welcome to the HBC Training Program
</h1>
<h3 align="center">
We are delighted to have you here!
</h3>


## Are you feeling lost and unsure about bioinformatic anaysis?

* Do you want to utilize high-throughput sequencing data in your research, but not really sure where to start?
* Does the idea of writing your own code for data analysis seem necessary, yet daunting?
* Do you need to brush up on what you already know about analysis of high-throughput sequencing data?

### Click on the following questions to expand them for the answers:

<details>
  <summary><b>What the heck is &#39;omics?</b></summary><br>
  Over the last 10-15 years many technological advances allow us to assess the entirety of a certain type of molecule(s) in an organsim. The resulting high-throughput data are called &#39;omics data. We can break &#39;omics down into 4 specific categories:<br><br>
<ul><li>genOMICS - The study of the complete set of <b>DNA</b> in an organism, single cells, or group of cells.</li>
<li>transcriptOMICS - The study of the complete set of <b>RNA</b> in an organism, single cells, or group of cells.</li>
<li>proteOMICS - The study of the complete set of <b>Proteins</b> in an organism, single cells, or group of cells.</li>
<li>metabolOMICS - The study of the complete set of <b>Metabolites</b> in an organism, single cells, or group of cells.</li></ul><br>
High-throughput data from even a single sample is considered &#39;omics data. However, we usually are looking at data from large number of biological samples (individuals, cell lines, etc).<br><br><hr />
</details>
<details>
  <summary><b>What is High-throughput Sequencing (HTS) or Next-generation Sequencing (NGS) data?</b></summary><br>
    <ul><li> <b> What is a Genome? <i>All of the DNA in an individual or a species</i> </b></li>
    <li> <b> What is a Transcriptome? <i>All of the RNA in an individual or a species (typically transcribed from DNA in individual cells)</i> </b></li></ul>

Both, genomes and transcriptomes, contain hundreds of millions or billions of nucleic acid units or <a href="https://en.wikipedia.org/wiki/Base_pair">bases/base pairs</a> (A,T,G,C). Compare that to the average length of a book, which is 375,000 characters. To &quot;read&quot; the sequence of As, Ts, Gs and Cs, we use different methods (a lot of which are PCR-based). The most basic way to sequence DNA is using <a href="https://en.wikipedia.org/wiki/Sanger_sequencing">Sanger Sequencing</a>. Reading those bases one at a time using the Sanger method takes a very long time with high per-base costs, but it was creatively utilized to complete the <a href="https://en.wikipedia.org/wiki/Human_Genome_Project">Human Genome Project (HGP) 1990 - 2003</a>. 

With the massive advancements spurred by the HGP, the field of &quot;next-generation&quot; sequencing exploded and had rapidly advanced such that now we are able to sequence a whole genome within a day, at a nominal cost. The analyses of these <b>big data</b> generated by HTS is the challenge at present.

<blockquote>Over the last few years the community is slowly replacing the term NGS (Next-generation Sequencing) with the more descriptive HTS (High-throughput Sequencing).</blockquote>

There are <a href="https://www.illumina.com/science/sequencing-method-explorer.html">hundreds of assays</a> that have been developed for HTS that have enabled us to gain deep insights into the working of a cell. The most commonly used HTS applications that you will encounter are:
<ul><li>Bulk RNA-seq</li>
<li>Single-cell RNA-seq</li>
<li>ChIP-seq</li>
<li>Whole genome sequencing</li>
<li>Exome sequencing</li>
<li>ATAC-seq</li>
<li>Single-cell ATAC-seq</li></ul>
<hr />
</details>
<details>
  <summary><b>How do clusters and HPC relate to analysis of HTS data?</b></summary><br>
  Let's return to our book example. If one book is 375,000 characters then 3.2 billion characters (the size of the human genome) translates to 8,533 books! While we might keep tens or even hundreds of books at our house, most people will never have thousands. 

<p align="center">
<img src="img/library.jpg" width="500">
</p>
<p align = "center">
Can you imagine dusting this?
</p>

It's the same with our local computer.  While we might keep small data files on our laptop, we don't want to clutter it up with huge data files. And this is just thinking about storage! Books or data sets need to be organized and kept track of as well. You might be able to alphabetize or organize a hundred books on your own but working with &gt;8,000 books would be overwhelming! The same goes for our computer. To organize billions of base pairs and make sense of our sequencing data we simply need more power. The Mac laptop I am writing this on has 10 cores (a single unit of processing available in our CPU; see below for more information). In comparison, a high perfomance computing (HPC) cluster might have hundreds or thousands of cores. That is a lot more processing capacity, more in line with the large amount of computational work we want to do!

Let's take a quick look at the basic architecture of a cluster environment and some cluster-specific jargon.

<p align="center">
<img src="img/cluster.png" width="500">
</p>

The above image reflects the many computers that make up a <b>&quot;cluster&quot;</b> of computers. Each individual computer in the cluster is usually a lot more powerful than any laptop or desktop computer we are used to working with, and is referred to as a <b>&quot;node&quot;</b> (instead of computer). Each node has a designated role, either for logging in or for performing computational analysis/work. <b>A given cluster will usually have a few login nodes and several compute nodes.</b> Each individual node in an HPC environment is a lot <b>more powerful</b> than any laptop or desktop computer we are used to working with. What we mean by <i>powerful</i> here is that each of these nodes have:<br>

  <ul><li>More memory (temporary storage)</li>
  <li>Many more, faster CPUs</li>
  <li>Each of those CPUs has many more cores</li></ul>

E.g. A cluster &quot;Node&quot; that has eight &quot;quad-core&quot; CPUs, means that node has 32 cores (ability to process 32 computations at a time).

The data on a cluster is also stored differently than what we are used to with our laptops and desktops, in that it is not computer- or node-specific storage, but it is external and is available to all the nodes in a cluster. This ensures that you don't have to worry about which node is working on your analysis.

<h3>Why use the cluster or an HPC environment?</h3>

<ol><li>A lot of software is designed to work with the resources on an HPC environment and is either unavailable for, or unusable on, a personal computer.</li>
<li>If you are performing analysis on large data files (e.g. high-throughput sequencing data), you should work on the cluster to avoid issues with memory and to get the analysis done a lot faster with the superior processing capacity. Essentially, a cluster has:<br>
    <ul><li>100s of cores for processing!</li>
    <li>100s of Gigabytes or Petabytes of storage!</li>
    <li>100s of Gigabytes of memory!</li></ul></li></ol>

<h3>Parallelization</h3>

Point #2 in the last section brings us to the idea of <b>parallelization</b> or parallel computing that enables us to efficiently use the resources available on the cluster.

<h4>One input file</h4>

Let's start with the most basic idea of processing 1 input file to generate 1 output (result) file. On a personal computer this would happen with a single core in the CPU. 

<p align="center">
<img src="img/serial_hpc_crop.png" width="50">
</p>

On a cluster we have access to many cores on a single node, so in theory we could split up the analysis of a single file into multiple distinct processes and use as many cores to speed up the generation of an output file. This is called <b>multithreading</b>, i.e. using multiple threads or cores. As you can imagine, multithreading can speed up how fast the analysis is performed! In the example below, the input file is analyzed using 8 cores, likely resulting in an 8-fold speed up!

<p align="center">
<img src="img/multithreaded_hpc.png" width="450">
</p>

<blockquote><b>Note:</b> Multithreading is done internally by analysis tools being employed, and <b>not</b> by manually splitting the input (except in very unusual circumstances).</blockquote>

<h4>Three input files</h4>

Now, what if we had 3 input files? Well, we could process these files <b>in serial</b>, i.e. use the same core(s) over and over again, as shown in the image below.

<p align="center">
<img src="img/serial_hpc_3samples.png" width="450">
</p>

This is great, but it is not as efficient as multithreading each analysis, and using a set of 8 cores for each of the three input samples. This is actually considered to be true parallelization.

<p align="center">
<img src="img/multithreaded_hpc_3samples.png" width="650">
</p>

With parallelization, several samples can be analysed at the same time!
<hr />
</details>
  
<details>
  <summary><b>What is shell and how does it relate to clusters?</b></summary><br>
So how might you actually use a cluster? Unfortunately you can't just walk up to where the cluster is stored and start using it. Clusters are accessed remotely, that means that you connect to the cluster from your own computer. You will do this from the <b>command line</b> or a text-based user interface. We are used to clicking on applications we want to use and selecting various commands from dropdown menus. Clusters do not work this way. Any task that you want a cluster to do has to be communicated through a text command.

<p align="center">
<img src="img/fasRC.jpeg" width="650">
</p>
<p align = "center">
The FAS-RC Cluster
</p>

If you have never taken a computer science course or worked with clusters before this will all be brand new to you. But don't worry, we have <a href="https://hbctraining.github.io/Intro-to-shell-flipped/schedule/links-to-lessons.html">courses for that</a>! 

For now let's just review the basics. To look at command line on your own computer you can open the Terminal program on Macs or for Windows download <a href="https://gitforwindows.org/">Git BASH</a> or similar application. The <b>shell</b> is what runs in these programs to interpret your commands. These programs all use <a href="https://en.wikipedia.org/wiki/Bash_Unix_shell">Bash</a>, a command language. As you get into HTS and computational work you will encounter a lot of languages such as Python, Perl, Fortran, R, C++, Java and more. You can think of these as being akin to human languages; French and English sound very different and have different syntax (the order of words) but can be used to convey the same message. At HBC training we recommend that you become familiar (or fluent) in bash and R to begin with. 
<hr />
</details>
<details>
  <summary><b>What is R and what can it do?</b></summary><br>
Why do we recommend R instead of other languages? According to <a href="https://www.r-project.org/about.html">R-project</a>, &quot;R is a language and environment for statistical computing and graphics.&quot; R is also a well developed and relatively simple language that is widely used among data scientists and people in STEM. Compelling arguements for learning R include:

<ul><li>It’s open-source. This means no fees or licenses are needed and you won't get any pop ups asking for money.</li>
<li>It’s platform-independent. This means that R runs on all operating systems (Mac, Windows, Linux) and R scripts written on on platform can be run on any other platform.</li>
<li>People write packages for R, especially in the field of bioinformatics. The R language has more than 10,000 packages stored in the CRAN repository, and that number is continuously increasing. Many packages for analyzing HTS data are written for R such as DESeq2 and Seurat among others.</li>
<li>Data wrangling, i.e., turning raw data into the desired format. Data wrangling is necessary for working with any &#39;omics data set and R has many packages that can turn unstructured, messy data into a structured format.</li>
<li>Great plotting programs. R has wonderful packages to make publication ready figures. We even have a <a href="https://hbctraining.github.io/Training-modules/publication_perfect/">workshop</a> devoted to it!</li>
<li>It’s great for statistics. Unlike SAS which is very costly, R is free and has many different statistical packages available.</li>
<li>You can use R for Machine Learning. R is ideal for machine learning operations such as regression and classification and even for artificial neural network development.</li>
<li>R is growing. R has a solid support program and help with issues is widely available. New packages and features are available regularly!</li></ul> 
<hr />
</details>
<details>
  <summary><b>Where do I go from here?</b></summary><br>
Hopefully you now feel like you have a grasp on some of these terms. If you want to start getting your hands wet, we recommend that you take our <a href="https://hbctraining.github.io/Intro-to-R-flipped/schedules/links-to-lessons.html">Intro to R Course</a> and the appropriate shell intro for the cluster you will use, either <a href="https://hbctraining.github.io/Intro-to-shell-flipped/schedule/links-to-lessons.html">O2</a> or <a href="https://hbctraining.github.io/Intro-to-shell-fasrc-flipped/schedule/links-to-lessons.html">FAS-RC</a>. You are free to take a workshop with us or work through the lessons yourself at your own pace. See our below for all of our offerings.
<hr />
</details>

The training team at the Harvard Chan Bioinformatics Core provides bioinformatics training in multiple formats, they can be broadly divided into the following: 

1. [Introduction to High-throughput sequencing (HTS) data analysis series](#introduction-to-high-throughput-sequeuncing-hts-data-analysis-series)
2. [Current topics in bioinformatics series](#current-topics-in-bioinformatics-series)

Our current workshops and courses are designed to help biologists become comfortable with using tools to analyse high-throughput data. We are slowly beginning to expand this repertoire to include training for researchers with more advanced bioinformatics skills. 

_See our **current workshop schedule** on our [training website](https://bioinformatics.sph.harvard.edu/upcoming-workshops)._

> NOTE: The tables below are also represented using a schematic figure which can be found [on this page here](training_overview_workflow.md).

## Introduction to high-throughput sequeuncing (HTS) data analysis series:

This series of workshops is divided into 2 categories, [Basic Data Skills](#basic-data-skills) and [Advanced Topics](#advanced-topics). The Basic workshops serve as the foundation that participants can build upon in the Advanced workshops and we will be offering these as pairs with the appropriate basic workshop preceding an advanced one. Please see below for a description of workshops under each of these two categories.

### Basic Data Skills:

These workshops provide an introduction to computational skills required for someone to get started with analyzing high-throughput sequencing data independently. These have no prerequisites and do not require any prior experience with programming.

| Topic and Link(s) to lessons | Prerequisites |
| :----: | :----: | 
| [Shell for Bioinformatics - O2 cluster](https://hbctraining.github.io/Shell-for-bioinformatics/) | None |
| [Introduction to R](https://hbctraining.github.io/Intro-to-R-flipped/schedules/links-to-lessons.html) | None |
| [Introduction to R (video tutorials)](https://projects.iq.harvard.edu/hcatrresource/) | None |
  
### Advanced Topics:

These are intensive workshops that instruct participants on how to design experiments, and efficiently manage & analyze data. They focus on the workflow for a specific type of next-generation sequencing application (i.e RNA-seq, ChIP-seq). *These workshops require participants to have taken one or more of the [Basic Data Skills workshops](#basic-data-skills) as listed in the table below.*
  
| Topic and Link(s) to lessons | Prerequisites |
| :----: | :----: |
| [Introduction to bulk RNA-seq: From reads to count matrix - O2 cluster](https://hbctraining.github.io/Intro-to-bulk-RNAseq/schedule/links-to-lessons.html) | Shell for Bioinformatics |
| [Introduction to Differential Gene Expression Analysis](https://hbctraining.github.io/Intro-to-DGE/)  | Introduction to R  |
| [Investigating chromatin biology using ChIP-seq and CUT&RUN - O2 cluster](https://hbctraining.github.io/Investigating-chromatin-biology-ChIPseq/) | Shell for Bioinformatics |
| [Introduction to single cell RNA-seq](https://hbctraining.github.io/Intro-to-scRNAseq/schedule/links-to-lessons.html) | Introduction to R |
| [Introduction to Variant Analysis](https://hbctraining.github.io/Intro-to-variant-analysis/) | Shell for Bioinformatics |
| [Tools for Reproducible Research](https://hbctraining.github.io/Tools-for-reproducible-research/) | Introduction to R |
| [Pseudobulk and related approaches for scRNA-seq analysis](https://hbctraining.github.io/Pseudobulk-for-scRNAseq/) | Introduction to R |
| [Introduction to Peak Analysis](https://github.com/hbctraining/Intro-to-peak-analysis) | Introduction to R |

***

## Current topics in bioinformatics series:

These workshops provide instruction on basic data skills as well as introduce new topics of interest to the community.

### R-based short workshops:

| Topic and Link(s) to lessons | Prerequisites |
|:---------------|:-------------:|
| [Foudations in R](https://hbctraining.github.io/Training-modules/IntroR) | None |
| [Practical Applications of R](https://hbctraining.github.io/Training-modules/IntroR_practical_online_resource) | Beginner R or [Completion of the Intro to R online resource](https://projects.iq.harvard.edu/hcatrresource/) |
| [Functional analysis of gene lists](https://hbctraining.github.io/Training-modules/DGE-functional-analysis) | Beginner R or [Intro to R workshop](https://hbctraining.github.io/Training-modules/IntroR) |
| [Reproducible Research using RMarkdown](https://hbctraining.github.io/Training-modules/Rmarkdown) | Beginner R or [Intro to R workshop](https://hbctraining.github.io/Training-modules/IntroR) |
| [Publication Perfect I: Data visualization basics with ggplot2](https://hbctraining.github.io/Training-modules/publication_perfect) | Beginner R or [Completion of the Intro to R online resource](https://projects.iq.harvard.edu/hcatrresource/) |
| [Publication Perfect II: Figure formatting in R](https://hbctraining.github.io/Training-modules/publication_perfect#part-ii) | [Publication Perfect: Part I](https://hbctraining.github.io/Training-modules/publication_perfect) |
| [Interact with your data using RShiny](https://hbctraining.github.io/Training-modules/RShiny/) | Beginner R or [Completion of the Intro to R online resource](https://projects.iq.harvard.edu/hcatrresource/) |


### Shell-based short workshops:

| Topic and Link(s) to lessons | Prerequisites |
|:---------------|:-------------:|
| [Foundations in Shell](https://hbctraining.github.io/Training-modules/Basic_shell) | None |
| [Intermediate Shell/Accelerate with Automation](https://hbctraining.github.io/Training-modules/Accelerate_with_automation/) | [Basic Shell](https://hbctraining.github.io/Training-modules/Basic_shell) |
| [Advanced Shell/Finding and Summarizing Data from Colossal Files](https://hbctraining.github.io/Training-modules/Finding_and_summarizing_colossal_files/) | [Basic Shell](https://hbctraining.github.io/Training-modules/Basic_shell) |
| [Tips and Tricks on O2](https://hbctraining.github.io/Training-modules/Tips_and_Tricks_on_O2/) | [Basic Shell](https://hbctraining.github.io/Training-modules/Basic_shell) |
| [“Track Changes” for Your Code: An Introduction to Git and GitHub](https://hbctraining.github.io/Training-modules/Git-Github/#track-changes-with-your-code-an-introduction-to-git-and-github) | No pre-requisite (GitHub Desktop) |
| [Coding with Others: Managing Conflicts on GitHub](https://hbctraining.github.io/Training-modules/Git-Github/#coding-with-others-managing-conflicts-on-github) | [“Track Changes” for Your Code](https://hbctraining.github.io/Training-modules/Git-Github/#track-changes-with-your-code-an-introduction-to-git-and-github) |
| [Accessing genomic reference and experimental sequencing data](https://hbctraining.github.io/Accessing_public_genomic_data) | [Basic Shell](https://hbctraining.github.io/Training-modules/Basic_shell)  |


### Other short workshops:

| Topic and Link(s) to lessons | Prerequisites |
|:---------------|:-------------:|
| [Introduction to Python](https://hbctraining.github.io/Training-modules/Python) | None |
| [Planning a bulk RNA-seq analysis: Part I](https://hbctraining.github.io/Training-modules/planning_successful_rnaseq#part-i) | None |
| [Planning a bulk RNA-seq analysis: Part II](https://hbctraining.github.io/Training-modules/planning_successful_rnaseq#part-ii) | None |
| [Make your (RNA-seq) data analysis reproducible](https://hbctraining.github.io/Training-modules/reproducible_analyses)- *Taught by [Julie Goldman](https://scholar.harvard.edu/julie_goldman) from Countway Library* | None |
| [Improving your (RNA-seq) data analysis using version control (Git) - In collaboration with HBC-RCS](https://hbctraining.github.io/versioning_data_scripts/) | None |

***

# Contact us:

**Email:** [hbctraining@hsph.harvard.edu](mailto:hbctraining@hsph.harvard.edu)

**Webpage:** [http://bioinformatics.sph.harvard.edu/training/](http://bioinformatics.sph.harvard.edu/training/)

*** 

*These materials have been developed by members of the teaching team at the [Harvard Chan Bioinformatics Core (HBC)](http://bioinformatics.sph.harvard.edu/) RRID:SCR_025373. These are open access materials distributed under the terms of the [Creative Commons Attribution license](https://creativecommons.org/licenses/by/4.0/) (CC BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.*

*A lot of time and effort went into the preparation of these materials. Citations help us understand the needs of the community, gain recognition for our work, and attract further funding to support our teaching activities. Thank you for citing the corresponding course (as suggested in its "Read Me" section) if it helped you in your data analysis.*
  
<!-- This content will not appear in the rendered Markdown -->
<!-- Removed links to FAS-RC:
 <li><a href="https://hbctraining.github.io/Intro-to-shell-fasrc-flipped/">Introduction to the command-line interface (shell) - FAS-RC cluster</a></li>
 <li><a href="https://hbctraining.github.io/Intro-to-rnaseq-fasrc-salmon-flipped/">Introduction to (bulk) RNA-seq using High-Performance Computing - FAS-RC cluster</a></li> -->
